{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4d1f30-c93b-41af-b508-9adb0f43f273",
   "metadata": {},
   "source": [
    "## Language model training (fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a48bf44-6a6b-4510-921b-8c53a5512d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, AutoConfig\n",
    "import torch\n",
    "import math\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da24399-0576-46f5-83d0-c5a71dbd8b11",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a732a3d6-8b3e-49c7-83f3-ca6a4da887ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did you hear about the Native American man tha...</td>\n",
       "      <td>He nearly drown in his own tea pee.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Did you hear about the Native American man tha...   \n",
       "1       What's the best anti diarrheal prescription?   \n",
       "2  What do you call a person who is outside a doo...   \n",
       "3  Which Star Trek character is a member of the m...   \n",
       "4  What's the difference between a bullet and a h...   \n",
       "\n",
       "                                Answer  \n",
       "0  He nearly drown in his own tea pee.  \n",
       "1                     Mycheexarphlexin  \n",
       "2                                 Matt  \n",
       "3                   Jean-Luc Pickacard  \n",
       "4        A bullet doesn't miss Harambe  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv\n",
    "jokes1 = pd.read_csv('./data/jokes.csv', usecols=['Question', 'Answer'])\n",
    "jokes2 = pd.read_csv('./data/jokes_score_name_clean.csv', usecols=['q', 'a'])\n",
    "df = jokes1.append(jokes2.rename(columns={\"q\": \"Question\", \"a\": \"Answer\"}), ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51601a6-a4bd-4d3c-a3ef-d77c17bb474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat question to answer and add special tokens\n",
    "df['text'] = '<|question|> ' + df['Question'] + '\\n<|answer|> ' + df['Answer'] + ' <|endoftext|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14440414-5b34-49b4-8fb2-ce10ff05b0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 154437\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 17160\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# load to dataset\n",
    "dataset = Dataset.from_pandas(df[['text']]).train_test_split(test_size=0.1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04e655-673b-4792-8c26-064096ff6135",
   "metadata": {},
   "source": [
    "### Causal Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ecc069e-f3f5-4e24-b347-03fa080b9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pretrained model for transfer learning (GPT2)\n",
    "model_checkpoint = \"distilgpt2\"\n",
    "\n",
    "# initialize tokenizer (BPE for GPT2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c568dd-00e9-4553-9f27-e326a74941b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7243ac95ba2847c4be970fb6ea9f4894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=155.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2003 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93fb9c2285041f88e1ad1e40ec27215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'])\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=1, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d982b809-5ded-4cc7-9dce-73c3188448a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527650304e764b1fb77a741084b88d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=155.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0316bfc9b76411b9fbb444d6487aa8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# concatenate text to chunks of a certain block size (reduce if GPU runs out of memory)\n",
    "block_size = 128\n",
    "\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aebb2190-e516-49b1-ba32-d3c46251e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize mlflow\n",
    "MLFLOW_SERVER_URL = 'http://127.0.0.1:5000/'\n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER_URL)\n",
    "experiment_name = 'experiment1'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f4addcf-2a16-408e-8ed5-24efd09d03d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at C:\\Users\\Yufung/.cache\\huggingface\\transformers\\f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at C:\\Users\\Yufung/.cache\\huggingface\\transformers\\43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 87597\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32850\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32850' max='32850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32850/32850 1:16:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.770800</td>\n",
       "      <td>2.685315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.694000</td>\n",
       "      <td>2.629530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.655500</td>\n",
       "      <td>2.613149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to experiment1\\checkpoint-500\n",
      "Configuration saved in experiment1\\checkpoint-500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-1000\n",
      "Configuration saved in experiment1\\checkpoint-1000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-1000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-1500\n",
      "Configuration saved in experiment1\\checkpoint-1500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-1500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-2000\n",
      "Configuration saved in experiment1\\checkpoint-2000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-2000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-2500\n",
      "Configuration saved in experiment1\\checkpoint-2500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-2500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-3000\n",
      "Configuration saved in experiment1\\checkpoint-3000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-3000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-3500\n",
      "Configuration saved in experiment1\\checkpoint-3500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-3500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-4000\n",
      "Configuration saved in experiment1\\checkpoint-4000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-4000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-4500\n",
      "Configuration saved in experiment1\\checkpoint-4500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-4500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-5000\n",
      "Configuration saved in experiment1\\checkpoint-5000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-5000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-5500\n",
      "Configuration saved in experiment1\\checkpoint-5500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-5500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-6000\n",
      "Configuration saved in experiment1\\checkpoint-6000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-6000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-6500\n",
      "Configuration saved in experiment1\\checkpoint-6500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-6500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-7000\n",
      "Configuration saved in experiment1\\checkpoint-7000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-7000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-7500\n",
      "Configuration saved in experiment1\\checkpoint-7500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-7500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-8000\n",
      "Configuration saved in experiment1\\checkpoint-8000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-8000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-8500\n",
      "Configuration saved in experiment1\\checkpoint-8500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-8500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-9000\n",
      "Configuration saved in experiment1\\checkpoint-9000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-9000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-9500\n",
      "Configuration saved in experiment1\\checkpoint-9500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-9500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-10000\n",
      "Configuration saved in experiment1\\checkpoint-10000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-10000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-10500\n",
      "Configuration saved in experiment1\\checkpoint-10500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-10500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9821\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to experiment1\\checkpoint-11000\n",
      "Configuration saved in experiment1\\checkpoint-11000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-11000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-11500\n",
      "Configuration saved in experiment1\\checkpoint-11500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-11500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-12000\n",
      "Configuration saved in experiment1\\checkpoint-12000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-12000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-12500\n",
      "Configuration saved in experiment1\\checkpoint-12500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-12500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-13000\n",
      "Configuration saved in experiment1\\checkpoint-13000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-13000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-13500\n",
      "Configuration saved in experiment1\\checkpoint-13500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-13500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-14000\n",
      "Configuration saved in experiment1\\checkpoint-14000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-14000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-14500\n",
      "Configuration saved in experiment1\\checkpoint-14500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-14500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-15000\n",
      "Configuration saved in experiment1\\checkpoint-15000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-15000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-15500\n",
      "Configuration saved in experiment1\\checkpoint-15500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-15500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-16000\n",
      "Configuration saved in experiment1\\checkpoint-16000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-16000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-16500\n",
      "Configuration saved in experiment1\\checkpoint-16500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-16500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-17000\n",
      "Configuration saved in experiment1\\checkpoint-17000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-17000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-17500\n",
      "Configuration saved in experiment1\\checkpoint-17500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-17500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-18000\n",
      "Configuration saved in experiment1\\checkpoint-18000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-18000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-18500\n",
      "Configuration saved in experiment1\\checkpoint-18500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-18500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-19000\n",
      "Configuration saved in experiment1\\checkpoint-19000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-19000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-19500\n",
      "Configuration saved in experiment1\\checkpoint-19500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-19500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-20000\n",
      "Configuration saved in experiment1\\checkpoint-20000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-20000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-20500\n",
      "Configuration saved in experiment1\\checkpoint-20500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-20500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-21000\n",
      "Configuration saved in experiment1\\checkpoint-21000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-21000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-21500\n",
      "Configuration saved in experiment1\\checkpoint-21500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-21500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9821\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to experiment1\\checkpoint-22000\n",
      "Configuration saved in experiment1\\checkpoint-22000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-22000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-22500\n",
      "Configuration saved in experiment1\\checkpoint-22500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-22500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-23000\n",
      "Configuration saved in experiment1\\checkpoint-23000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-23000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-23500\n",
      "Configuration saved in experiment1\\checkpoint-23500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-23500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-24000\n",
      "Configuration saved in experiment1\\checkpoint-24000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-24000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-24500\n",
      "Configuration saved in experiment1\\checkpoint-24500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-24500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-25000\n",
      "Configuration saved in experiment1\\checkpoint-25000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-25000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-25500\n",
      "Configuration saved in experiment1\\checkpoint-25500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-25500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-26000\n",
      "Configuration saved in experiment1\\checkpoint-26000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-26000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-26500\n",
      "Configuration saved in experiment1\\checkpoint-26500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-26500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-27000\n",
      "Configuration saved in experiment1\\checkpoint-27000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-27000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-27500\n",
      "Configuration saved in experiment1\\checkpoint-27500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-27500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-28000\n",
      "Configuration saved in experiment1\\checkpoint-28000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-28000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-28500\n",
      "Configuration saved in experiment1\\checkpoint-28500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-28500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-29000\n",
      "Configuration saved in experiment1\\checkpoint-29000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-29000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-29500\n",
      "Configuration saved in experiment1\\checkpoint-29500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-29500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-30000\n",
      "Configuration saved in experiment1\\checkpoint-30000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-30000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-30500\n",
      "Configuration saved in experiment1\\checkpoint-30500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-30500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-31000\n",
      "Configuration saved in experiment1\\checkpoint-31000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-31000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-31500\n",
      "Configuration saved in experiment1\\checkpoint-31500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-31500\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-32000\n",
      "Configuration saved in experiment1\\checkpoint-32000\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-32000\\pytorch_model.bin\n",
      "Saving model checkpoint to experiment1\\checkpoint-32500\n",
      "Configuration saved in experiment1\\checkpoint-32500\\config.json\n",
      "Model weights saved in experiment1\\checkpoint-32500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9821\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9821\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1228' max='1228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1228/1228 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 13.64\n"
     ]
    }
   ],
   "source": [
    "# run experiment\n",
    "with mlflow.start_run():\n",
    "    model = AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
    "    model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        experiment_name,\n",
    "        evaluation_strategy='epoch',\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=lm_datasets[\"train\"],\n",
    "        eval_dataset=lm_datasets[\"test\"],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate()\n",
    "    perplexity = math.exp(eval_results['eval_loss'])\n",
    "    print(f'Perplexity: {perplexity:.2f}')\n",
    "\n",
    "    # save the metric values\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"weight_decay\", weight_decay)\n",
    "    mlflow.log_metric(\"perplexity\", perplexity)\n",
    "    mlflow.pytorch.log_model(model, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e6f71-c183-4f42-91d6-bb0b2fe00dcb",
   "metadata": {},
   "source": [
    "### Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465f6622-be0b-4157-a8b0-b034bcd7769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load logged model\n",
    "logged_model = 'runs:/466254aedb4846549fa1acbfaceb4471/models'\n",
    "device = torch.device('cpu')\n",
    "loaded_model = mlflow.pytorch.load_model(logged_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8fb659e-e5ba-4d0b-b3ce-f4cbb4452010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5059bfc-7ada-4d97-98fd-3281b4a104cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the best type of person to be a monk?\n",
      "Answer: The one who's the most. \n"
     ]
    }
   ],
   "source": [
    "# tokenize input text\n",
    "sample_input = 'Who is'\n",
    "input_ids = tokenizer.encode('<|question|> ' + sample_input, return_tensors='pt')\n",
    "\n",
    "# Top-K and Top-p sampling\n",
    "sample_outputs = loaded_model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=100,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1\n",
    ")\n",
    "\n",
    "# decode output\n",
    "sample_output = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "print(sample_output.replace('<|question|>', 'Question:').replace('<|answer|>', 'Answer:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca527011-b34c-4854-9024-8b285898d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as mlflow model\n",
    "mlflow.pytorch.save_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8de992-9d28-4f75-8d89-9f045b685900",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')\n",
    "config = AutoConfig.from_pretrained('distilgpt2')\n",
    "\n",
    "tokenizer.save_pretrained('./')\n",
    "config.save_pretrained('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63160761-b621-49a9-85bb-937bfc7692ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsmlenv",
   "language": "python",
   "name": "lsmlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
